{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ettoday 網路爬蟲實作練習\n",
    "\n",
    "\n",
    "* 能夠利用 Request + BeatifulSour 撰寫爬蟲，並存放到合適的資料結構\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "根據範例：\n",
    "\n",
    "1. 取出今天所有的新聞\n",
    "2. 取出現在時間兩小時內的新聞\n",
    "3. 根據範例，取出三天前下午三點到五點的新聞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 取出今天所有的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-06 18:18:00\n2020-02-06 18:04:00\n2020-02-06 17:56:00\n2020-02-06 17:56:00\n2020-02-06 17:49:00\n2020-02-06 17:43:00\n2020-02-06 17:04:00\n2020-02-06 16:59:00\n2020-02-06 16:53:00\n2020-02-05 17:17:00\n"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "yesterday = datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "# print(yesterday)\n",
    "browser = webdriver.Chrome(executable_path='chromedriver')\n",
    "browser.get(\"https://www.ettoday.net/news/news-list.htm\")\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.5)\n",
    "    browser.execute_script(\"window.scrollTo(0, 1000000);\")\n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, \"lxml\")\n",
    "    news_time = soup.find(class_=\"part_list_2\").find_all('h3')[-1].find(class_=\"date\").text\n",
    "    news_time = datetime.strptime(news_time, '%Y/%m/%d %H:%M')\n",
    "    print(news_time)\n",
    "    if news_time < yesterday:\n",
    "        break\n",
    "\n",
    "# for d in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "#     print(d.find(class_=\"date\").text, d.find_all('a')[-1].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>news</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020/02/06 20:42</td>\n      <td>民眾黨譴責WHO矮化台灣「請適可而止」　大陸不應用蠻橫手段阻撓</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020/02/06 20:42</td>\n      <td>首班包機竟排除他！重型血友病患仍受困湖北　「救命藥」快用完了</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020/02/06 20:42</td>\n      <td>快訊／疫情有異？　中央疫情指揮中心2130記者會說明</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020/02/06 20:41</td>\n      <td>史上次高！2019年國銀對中小企業放款4,599億　這5加銀行增加最多</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020/02/06 20:41</td>\n      <td>還有900人想返台！湖北台辦每位聯繫了…發放口罩、消毒水</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>2020/02/06 16:57</td>\n      <td>猛飆致勝三分球領12連勝　伊巴卡：教練叫我持續自信投</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>2020/02/06 16:56</td>\n      <td>多國急喊卡入境中國航班！華春瑩直指「人為製造恐慌」…嚴厲回應了</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>2020/02/06 16:56</td>\n      <td>宋兆文／國軍第一個能獨立戰鬥的陸軍聯合兵種營</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>2020/02/06 16:54</td>\n      <td>快訊／徐正文遭停止黨權　國民黨澄清不介入第二次包機</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>2020/02/06 16:53</td>\n      <td>《叫小賀》威哥同居狼人殺女神！　梁以辰霸氣：會好好照顧他</td>\n    </tr>\n  </tbody>\n</table>\n<p>210 rows × 2 columns</p>\n</div>",
      "text/plain": "                 time                                 news\n0    2020/02/06 20:42      民眾黨譴責WHO矮化台灣「請適可而止」　大陸不應用蠻橫手段阻撓\n1    2020/02/06 20:42       首班包機竟排除他！重型血友病患仍受困湖北　「救命藥」快用完了\n2    2020/02/06 20:42           快訊／疫情有異？　中央疫情指揮中心2130記者會說明\n3    2020/02/06 20:41  史上次高！2019年國銀對中小企業放款4,599億　這5加銀行增加最多\n4    2020/02/06 20:41         還有900人想返台！湖北台辦每位聯繫了…發放口罩、消毒水\n..                ...                                  ...\n205  2020/02/06 16:57           猛飆致勝三分球領12連勝　伊巴卡：教練叫我持續自信投\n206  2020/02/06 16:56      多國急喊卡入境中國航班！華春瑩直指「人為製造恐慌」…嚴厲回應了\n207  2020/02/06 16:56               宋兆文／國軍第一個能獨立戰鬥的陸軍聯合兵種營\n208  2020/02/06 16:54            快訊／徐正文遭停止黨權　國民黨澄清不介入第二次包機\n209  2020/02/06 16:53         《叫小賀》威哥同居狼人殺女神！　梁以辰霸氣：會好好照顧他\n\n[210 rows x 2 columns]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html_source = browser.page_source\n",
    "# soup = BeautifulSoup(html_source, \"lxml\")\n",
    "today_news = []\n",
    "for d in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "    news_time\n",
    "    if datetime.strptime(d.find(class_=\"date\").text, '%Y/%m/%d %H:%M') < yesterday:\n",
    "        break\n",
    "    # print(d.find(class_=\"date\").text, d.find_all('a')[-1].text)\n",
    "    today_news.append({\n",
    "        \"time\":d.find(class_=\"date\").text, \n",
    "        \"news\":d.find_all('a')[-1].text\n",
    "        })\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(today_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 取出現在時間兩小時內的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>news</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020/02/06 20:42</td>\n      <td>民眾黨譴責WHO矮化台灣「請適可而止」　大陸不應用蠻橫手段阻撓</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020/02/06 20:42</td>\n      <td>首班包機竟排除他！重型血友病患仍受困湖北　「救命藥」快用完了</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020/02/06 20:42</td>\n      <td>快訊／疫情有異？　中央疫情指揮中心2130記者會說明</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020/02/06 20:41</td>\n      <td>史上次高！2019年國銀對中小企業放款4,599億　這5加銀行增加最多</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020/02/06 20:41</td>\n      <td>還有900人想返台！湖北台辦每位聯繫了…發放口罩、消毒水</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>2020/02/06 18:51</td>\n      <td>黑喵一開心就「小碎步」跳踢踏舞　萬名網友萌暈：太神奇了！</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>2020/02/06 18:48</td>\n      <td>快訊／蔡英文任命李俊俋為總統府副秘書長　施克和另有任用</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>2020/02/06 18:46</td>\n      <td>HBL／淡商力圖重返榮耀　8強以防守起家</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>2020/02/06 18:46</td>\n      <td>又有冷氣團！明起變天「2時間點」急凍12°C　下周四更強鋒面...全台有雨</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>2020/02/06 18:45</td>\n      <td>寶貝兒從陸返台　婦隱瞞接觸史！醫急喊「不要當防疫漏洞」：病患應誠實</td>\n    </tr>\n  </tbody>\n</table>\n<p>71 rows × 2 columns</p>\n</div>",
      "text/plain": "                time                                   news\n0   2020/02/06 20:42        民眾黨譴責WHO矮化台灣「請適可而止」　大陸不應用蠻橫手段阻撓\n1   2020/02/06 20:42         首班包機竟排除他！重型血友病患仍受困湖北　「救命藥」快用完了\n2   2020/02/06 20:42             快訊／疫情有異？　中央疫情指揮中心2130記者會說明\n3   2020/02/06 20:41    史上次高！2019年國銀對中小企業放款4,599億　這5加銀行增加最多\n4   2020/02/06 20:41           還有900人想返台！湖北台辦每位聯繫了…發放口罩、消毒水\n..               ...                                    ...\n66  2020/02/06 18:51           黑喵一開心就「小碎步」跳踢踏舞　萬名網友萌暈：太神奇了！\n67  2020/02/06 18:48            快訊／蔡英文任命李俊俋為總統府副秘書長　施克和另有任用\n68  2020/02/06 18:46                   HBL／淡商力圖重返榮耀　8強以防守起家\n69  2020/02/06 18:46  又有冷氣團！明起變天「2時間點」急凍12°C　下周四更強鋒面...全台有雨\n70  2020/02/06 18:45      寶貝兒從陸返台　婦隱瞞接觸史！醫急喊「不要當防疫漏洞」：病患應誠實\n\n[71 rows x 2 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html_source = browser.page_source\n",
    "# soup = BeautifulSoup(html_source, \"lxml\")\n",
    "two_h_ago = datetime.now() - timedelta(hours=2)\n",
    "two_h_news = []\n",
    "# print(two_h_ago)\n",
    "for d in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "    if datetime.strptime(d.find(class_=\"date\").text, '%Y/%m/%d %H:%M') < two_h_ago:\n",
    "        break\n",
    "    # print(d.find(class_=\"date\").text, d.find_all('a')[-1].text)\n",
    "    two_h_news.append({\n",
    "    \"time\":d.find(class_=\"date\").text, \n",
    "    \"news\":d.find_all('a')[-1].text\n",
    "    })\n",
    "import pandas as pd\n",
    "pd.DataFrame(two_h_news)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 根據範例，取出三天前下午三點到五點的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-06 18:18:00\n2020-02-06 18:04:00\n2020-02-06 18:04:00\n2020-02-06 17:59:00\n2020-02-06 17:50:00\n2020-02-06 17:45:00\n2020-02-06 17:38:00\n2020-02-06 17:30:00\n2020-02-06 17:17:00\n2020-02-06 17:04:00\n2020-02-06 16:59:00\n2020-02-06 16:54:00\n2020-02-06 16:44:00\n2020-02-06 16:38:00\n2020-02-06 16:32:00\n2020-02-06 16:24:00\n2020-02-06 16:15:00\n2020-02-06 16:08:00\n2020-02-06 16:00:00\n2020-02-06 15:52:00\n2020-02-06 15:46:00\n2020-02-06 15:34:00\n2020-02-06 15:24:00\n2020-02-06 15:18:00\n2020-02-06 15:09:00\n2020-02-06 15:01:00\n2020-02-06 14:46:00\n2020-02-06 14:42:00\n2020-02-06 14:30:00\n2020-02-06 14:19:00\n2020-02-06 14:10:00\n2020-02-06 14:03:00\n2020-02-06 13:49:00\n2020-02-06 13:34:00\n2020-02-06 13:26:00\n2020-02-06 13:11:00\n2020-02-06 12:59:00\n2020-02-06 12:50:00\n2020-02-06 12:40:00\n2020-02-06 12:32:00\n2020-02-06 12:23:00\n2020-02-06 12:14:00\n2020-02-06 12:05:00\n2020-02-06 12:01:00\n2020-02-06 11:54:00\n2020-02-06 11:48:00\n2020-02-06 11:41:00\n2020-02-06 11:34:00\n2020-02-06 11:23:00\n2020-02-06 11:15:00\n2020-02-06 11:09:00\n2020-02-06 11:04:00\n2020-02-06 10:55:00\n2020-02-06 10:46:00\n2020-02-06 10:30:00\n2020-02-06 10:20:00\n2020-02-06 10:12:00\n2020-02-06 09:55:00\n2020-02-06 09:40:00\n2020-02-06 09:17:00\n2020-02-06 08:58:00\n2020-02-06 08:20:00\n2020-02-06 07:22:00\n2020-02-06 06:31:00\n2020-02-06 03:37:00\n2020-02-06 00:40:00\n2020-02-06 00:04:00\n2020-02-05 23:24:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n2020-02-05 22:47:00\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8918f8fb4570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.ettoday.net/news/news-list.htm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window.scrollTo(0, 1000000);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhtml_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "three_d_ago = datetime.now() - timedelta(days=3)\n",
    "range_start = three_d_ago.replace(hour=15, minute=0, second=0, microsecond=0)\n",
    "range_end = three_d_ago.replace(hour=17, minute=0, second=0, microsecond=0)\n",
    "range_news = []\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='chromedriver')\n",
    "browser.get(\"https://www.ettoday.net/news/news-list.htm\")\n",
    "while True:\n",
    "    time.sleep(0.5)\n",
    "    browser.execute_script(\"window.scrollTo(0, 1000000);\")\n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, \"lxml\")\n",
    "    news_time = soup.find(class_=\"part_list_2\").find_all('h3')[-1].find(class_=\"date\").text\n",
    "    news_time = datetime.strptime(news_time, '%Y/%m/%d %H:%M')\n",
    "    print(news_time)\n",
    "    if news_time < range_start:\n",
    "        break\n",
    "#最晚的新聞依舊不在指定的時間範圍內，無法達成題目要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "    news_time = datetime.strptime(d.find(class_=\"date\").text, '%Y/%m/%d %H:%M')\n",
    "    if news_time < range_start:\n",
    "        break\n",
    "    # print(d.find(class_=\"date\").text, d.find_all('a')[-1].text)\n",
    "    if news_time < range_end:\n",
    "        range_news.append({\n",
    "        \"time\":d.find(class_=\"date\").text, \n",
    "        \"news\":d.find_all('a')[-1].text\n",
    "        })\n",
    "import pandas as pd\n",
    "pd.DataFrame(range_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}