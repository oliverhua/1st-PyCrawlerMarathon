{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTT 網路爬蟲實作練習\n",
    "\n",
    "\n",
    "* 能夠利用 Request + BeatifulSour 撰寫爬蟲，並存放到合適的資料結構\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "根據範例 ，完成以下問題：\n",
    "\n",
    "* ① 印出最新文章的「作者」「標題」「時間」\n",
    "* ② 印出第一頁所有文章的「作者」「標題」「時間」\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① 印出最新文章的「作者」「標題」「時間」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'作者': 'currykukuo (陳菊濕汗)', '標題': '[花邊] Russell：擺脫不掉交易流言，但已經能自在面對這種處境了', '時間': datetime.datetime(2020, 2, 5, 1, 1, 34)}\n"
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/NBA/index.html'\n",
    "r = requests.get(url).text\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "a = []\n",
    "for i in soup.findAll(class_=\"title\"):\n",
    "    try:\n",
    "        url = \"https://www.ptt.cc/\" + i.find('a')[\"href\"]\n",
    "    except:\n",
    "        continue\n",
    "    r = requests.get(url).text\n",
    "    s = BeautifulSoup(r, \"lxml\")\n",
    "    try:\n",
    "        data = s.findAll(class_=\"article-meta-value\")\n",
    "        author = data[0].text\n",
    "        title = data[2].text\n",
    "        time = data[3].text\n",
    "    except:\n",
    "        continue\n",
    "    a.append({\n",
    "        \"作者\" : author,\n",
    "        \"標題\"  : title,\n",
    "        \"時間\"   : datetime.strptime(time, \"%a %b %d %H:%M:%S %Y\")\n",
    "    })\n",
    "a.sort(key=lambda x : x[\"時間\"], reverse = True)\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② 印出第一頁所有文章的「作者」「標題」「時間」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'作者': 'currykukuo (陳菊濕汗)', '標題': '[花邊] Russell：擺脫不掉交易流言，但已經能自在面對這種處境了', '時間': datetime.datetime(2020, 2, 5, 1, 1, 34)}\n{'作者': 'WKC1799 (先知總是孤獨的)', '標題': 'Re: [討論] MJ是不是不太教人打球？', '時間': datetime.datetime(2020, 2, 5, 0, 58, 25)}\n{'作者': 's27052705 (小飽)', '標題': '[情報] Shams：尼克將Knox加入與勇士間關於Dlo', '時間': datetime.datetime(2020, 2, 5, 0, 10, 15)}\n{'作者': 'Gotham (萬惡之城)', '標題': '[新聞] 沒唐西奇打更好？ KP：這是我的課題', '時間': datetime.datetime(2020, 2, 4, 23, 50, 11)}\n{'作者': \"UCAthena (Let's go __)\", '標題': '[情報] Morant回擊Curry', '時間': datetime.datetime(2020, 2, 4, 23, 43, 31)}\n{'作者': 'cidexin (月娥)', '標題': 'Re: [討論] kobe\"老大\"這綽號是怎麼來的?', '時間': datetime.datetime(2020, 2, 4, 23, 14, 48)}\n{'作者': 'Frobel (幼稚教育之父)', '標題': '[情報] Bradley Beal巫師隊史得分超越John Wall', '時間': datetime.datetime(2020, 2, 4, 23, 9, 13)}\n{'作者': 'Acetoxy (阿斯)', '標題': '[情報] SEASON Schedule 賽程 February 19–20', '時間': datetime.datetime(2020, 1, 31, 22, 36, 43)}\n{'作者': 'qazwsx879345 (Rajon Rondo)', '標題': '[公告] 版主上任相關事項', '時間': datetime.datetime(2019, 10, 25, 10, 44, 3)}\n{'作者': 'Vedan (味丹)', '標題': '[公告] 樂透取消及未來不再開啟樂透', '時間': datetime.datetime(2019, 6, 24, 15, 8, 2)}\n"
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i, end= \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ 試著爬爬看其他版的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[{'作者': 'eric19910325 (翔)', '標題': '荷蘭Wageningen就業機會', '時間': 'Sat Feb  1 20:06:33 2020'}, {'作者': 'tpmlref5 (北市圖留學資料中心)', '標題': '[情報] 3/7北市圖西班牙交換分享講座，歡迎參加', '時間': 'Sun Feb  2 09:57:56 2020'}, {'作者': 'KouChan (每天都要尻)', '標題': '[問題] UTD的錄取通知可以放多久?', '時間': 'Sun Feb  2 14:01:07 2020'}, {'作者': 'IVWSVIIRMT (倒影)', '標題': '[問題] 在台灣看診的影像資料', '時間': 'Sun Feb  2 14:33:06 2020'}, {'作者': 'barriel (松竹梅)', '標題': '[問題] 紐約的供應鏈碩士學校選擇', '時間': 'Mon Feb  3 10:38:16 2020'}, {'作者': 'valerieshu (^ ^)', '標題': '[問題] 精算師FSA 申請美國學校', '時間': 'Mon Feb  3 12:44:35 2020'}, {'作者': 'rabbitbibu (BIBU)', '標題': '[情報] UCSD Grad Housing', '時間': 'Mon Feb  3 15:38:35 2020'}, {'作者': 'rabbitbibu (BIBU)', '標題': '[尋人] Duke DSCB program 學長姐', '時間': 'Tue Feb  4 00:38:57 2020'}, {'作者': 'wfgl6 (wfgl6)', '標題': '[情報] 美國學校畢業換校的另一種簽證選擇', '時間': 'Tue Feb  4 10:23:36 2020'}, {'作者': 'ron0908 (榮恩)', '標題': '[公告] 買賣書籍/團報/帳號/課程/帳號  請在此推文', '時間': 'Mon Dec 20 17:21:06 2010'}, {'作者': 'ron0908 (榮恩)', '標題': '[公告] 新手常見Q&A (不定時補完)', '時間': 'Mon Sep  5 04:24:28 2011'}, {'作者': 'aznchat100 (aznchat100)', '標題': 'Re: [情報] 留學版全文搜尋工具(持續更新)', '時間': 'Thu May 11 10:35:27 2017'}, {'作者': 'ron0908 (榮恩)', '標題': 'Re: [公告] 留學板板規v2.3 (2018.08.05修改)', '時間': 'Sun Aug  5 16:54:04 2018'}, {'作者': 'ron0908 (榮恩)', '標題': 'Re: [公告] 開放admission, rejection推文', '時間': 'Sun Jan  5 10:38:40 2020'}]\n"
    }
   ],
   "source": [
    "url = 'https://www.ptt.cc/bbs/studyabroad/index.html'\n",
    "r = requests.get(url).text\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "a = []\n",
    "# print(soup)\n",
    "for i in soup.findAll(class_=\"title\"):\n",
    "    try:\n",
    "        url = \"https://www.ptt.cc/\" + i.find('a')[\"href\"]\n",
    "    except:\n",
    "        continue\n",
    "    r = requests.get(url).text\n",
    "    s = BeautifulSoup(r, \"lxml\")\n",
    "    try:\n",
    "        data = s.findAll(class_=\"article-meta-value\")\n",
    "        author = data[0].text\n",
    "        title = data[2].text\n",
    "        time = data[3].text\n",
    "    except:\n",
    "        continue\n",
    "    a.append({\n",
    "        \"作者\" : author,\n",
    "        \"標題\"  : title,\n",
    "        \"時間\"   : time\n",
    "    })\n",
    "print(a) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}